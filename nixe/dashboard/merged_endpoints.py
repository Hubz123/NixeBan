# nixe/dashboard/merged_endpoints.py\n# Register additional endpoints WITHOUT requiring a global `app`.\n# Endpoints:\n#  - POST /dashboard/api/phash/upload       (file or {"url": ...} → pHash → blocklist.json)\n#  - GET  /dashboard/api/banned_users       (sqlite/jsonl ban history)\n#  - POST /dashboard/api/metrics-ingest     (bot pushes metrics)\n#  - GET  /dashboard/api/metrics            (read metrics + host fallback)\n\nimport os\nimport os, io, json, time, re, sqlite3\nfrom datetime import datetime\nfrom flask import request, jsonify, current_app\n\ntry:\n    from PIL import Image as _PILImage\n    import imagehash as _imgHash\nexcept Exception:\n    _PILImage = None\n    _imgHash = None\n\ntry:\n    import requests as _req\nexcept Exception:\n    _req = None\n\ndef _data_dir():\n    return os.getenv("DATA_DIR") or os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "data")\n\ndef _ensure_dir(p:str) -> str:\n    os.makedirs(p, exist_ok=True); return p\n\ndef _now(): return int(time.time())\n\ndef _ts_human(ts=None):\n    ts = ts or _now()\n    try: return datetime.fromtimestamp(int(ts)).strftime("%Y-%m-%d %H:%M:%S")\n    except Exception: return str(ts)\n\ndef _compute_phash(pil):\n    if pil is None: return None\n    if _imgHash is not None:\n        try: return str(_imgHash.phash(pil))\n        except Exception: pass\n    im = pil.convert("L").resize((8,8))\n    px = list(im.getdata()); avg = sum(px)/len(px)\n    bits = ''.join('1' if p>avg else '0' for p in px)\n    return hex(int(bits,2))[2:].rjust(16, '0')\n\ndef _blocklist_file():\n    return os.path.join(_data_dir(), "phish_lab", "phash_blocklist.json")\n\ndef _blocklist_read():\n    f = _blocklist_file()\n    if os.path.exists(f):\n        try: return json.load(open(f, "r", encoding="utf-8"))\n        except Exception: return []\n    return []\n\ndef _blocklist_append(val):\n    arr = _blocklist_read()\n    if val and val not in arr:\n        _ensure_dir(os.path.dirname(_blocklist_file()))\n        json.dump(arr + [val], open(_blocklist_file(), "w", encoding="utf-8"), indent=2)\n        return len(arr) + 1\n    return len(arr)\n\ndef _bans_sqlite_rows(limit=50):\n    db = os.path.join(_data_dir(), "bans.sqlite")\n    if not os.path.exists(db): return []\n    conn = sqlite3.connect(db); conn.row_factory = sqlite3.Row\n    cur = conn.cursor(); rows = []\n    try:\n        tabs = [r[0] for r in cur.execute("SELECT name FROM sqlite_master WHERE type='table'")]\n        cand = [t for t in tabs if re.search(r"ban", t, re.I)] or tabs\n        for t in cand:\n            cols = [r[1] for r in cur.execute(f"PRAGMA table_info({t})")]\n            col_uid = next((c for c in cols if c.lower() in ("user_id","userid","member_id","target_id")), None)\n            col_name = next((c for c in cols if c.lower() in ("username","user_name","name","display_name")), None)\n            col_reason = next((c for c in cols if c.lower() in ("reason","ban_reason")), None)\n            col_ts = next((c for c in cols if c.lower() in ("created_at","ts","timestamp","time")), None)\n            col_mod = next((c for c in cols if c.lower() in ("moderator","mod","actor","staff")), None)\n            if not col_uid and not col_name: continue\n            order_col = col_ts or "rowid"\n            q = f"SELECT {', '.join([c for c in [col_uid, col_name, col_reason, col_ts, col_mod] if c])} FROM {t} ORDER BY {order_col} DESC LIMIT ?"\n            for r in cur.execute(q, (limit,)):\n                d = dict(r)\n                rows.append({\n                    "user_id": d.get(col_uid) if col_uid else None,\n                    "username": d.get(col_name) if col_name else None,\n                    "reason": d.get(col_reason) if col_reason else None,\n                    "time": d.get(col_ts) if col_ts else None,\n                    "time_human": _ts_human(d.get(col_ts)) if col_ts else None,\n                    "mod": d.get(col_mod) if col_mod else None,\n                })\n            if rows: break\n    except Exception:\n        pass\n    finally:\n        conn.close()\n    return rows\n\ndef _bans_json_rows(limit=50):\n    for name in ("ban_events.jsonl","banlog.jsonl","ban_events.json"):\n        f = os.path.join(_data_dir(), name)\n        if not os.path.exists(f): continue\n        rows = []\n        try:\n            if f.endswith(".jsonl"):\n                for line in open(f,"r",encoding="utf-8").readlines()[::-1]:\n                    if not line.strip(): continue\n                    try: j = json.loads(line)\n                    except Exception: continue\n                    rows.append({\n                        "user_id": j.get("user_id") or j.get("uid"),\n                        "username": j.get("username") or j.get("name"),\n                        "reason": j.get("reason"),\n                        "time": j.get("ts") or j.get("time"),\n                        "time_human": _ts_human(j.get("ts") or j.get("time")),\n                        "mod": j.get("moderator") or j.get("mod"),\n                    })\n                    if len(rows) >= limit: break\n            else:\n                arr = json.load(open(f,"r",encoding="utf-8"))\n                for j in arr[::-1][:limit]:\n                    rows.append({\n                        "user_id": j.get("user_id") or j.get("uid"),\n                        "username": j.get("username") or j.get("name"),\n                        "reason": j.get("reason"),\n                        "time": j.get("ts") or j.get("time"),\n                        "time_human": _ts_human(j.get("ts") or j.get("time")),\n                        "mod": j.get("moderator") or j.get("mod"),\n                    })\n        except Exception:\n            continue\n        if rows: return rows\n    return []\n\ndef register_merged_endpoints(app):\n    # Handlers (closures use helper fns above)\n    def _phash_upload():\n        try:\n            raw = None; fname = None\n            f = request.files.get("file")\n            if f and f.filename:\n                raw = f.read()\n                fname = re.sub(r"[^A-Za-z0-9._-]+","_", f.filename)\n            if raw is None and request.is_json:\n                url = (request.json or {}).get("url","").strip()\n                if url and _req is not None:\n                    r = _req.get(url, timeout=10); r.raise_for_status()\n                    raw = r.content; fname = "fromurl_" + str(_now()) + ".png"\n            if raw is None:\n                return jsonify({"ok":False, "error":"no-file-or-url"}), 400\n\n            up_dir = _ensure_dir(os.path.join(_data_dir(), "uploads", "phish-lab"))\n            pil = _PILImage.open(io.BytesIO(raw)).convert("RGBA") if _PILImage else None\n            ph = _compute_phash(pil) if pil is not None else None\n            dest = os.path.join(up_dir, f"{_now()}_{fname or 'image.png'}")\n            if pil is not None: pil.save(dest)\n            else: open(dest, "wb").write(raw)\n            total = _blocklist_append(ph)\n            return jsonify({"ok":True, "phash":ph, "saved":dest, "blocklist_total": total})\n        except Exception as e:\n            current_app.logger.exception("phash upload failed")\n            return jsonify({"ok":False, "error": str(e)}), 500\n\n    def _metrics_ingest():\n        need = os.getenv("METRICS_INGEST_TOKEN","")\n        got = request.headers.get("X-Token","")\n        if need and need != got:\n            return jsonify({"ok":False, "error":"unauthorized"}), 401\n        try:\n            data = request.get_json(force=True, silent=True) or {}\n            f = os.path.join(_data_dir(), "live_metrics.json")\n            _ensure_dir(os.path.dirname(f))\n            data["ts"] = _now()\n            json.dump(data, open(f,"w",encoding="utf-8"), indent=2)\n            return jsonify({"ok":True})\n        except Exception as e:\n            current_app.logger.exception("metrics ingest failed")\n            return jsonify({"ok":False, "error": str(e)}), 500\n\n    def _metrics_get():\n        f = os.path.join(_data_dir(), "live_metrics.json")\n        data = {}\n        if os.path.exists(f):\n            try: data = json.load(open(f,"r",encoding="utf-8"))\n            except Exception: data = {}\n        resp = {\n            "guilds": data.get("guilds") or data.get("guild_count") or 0,\n            "members": data.get("members") or 0,\n            "online": data.get("online") or 0,\n            "channels": data.get("channels") or 0,\n            "threads": data.get("threads") or 0,\n            "latency_ms": data.get("latency_ms") or data.get("ping_ms") or 0,\n            "ts": data.get("ts"),\n        }\n        try:\n            import psutil\n            resp["cpu_percent"] = psutil.cpu_percent(interval=0.0)\n            resp["ram_mb"] = round(psutil.virtual_memory().used/1024/1024)\n        except Exception:\n            pass\n        return jsonify(resp)\n\n    def _banned_users():\n        limit = max(1, min(200, int(request.args.get("limit", 50))))\n        rows = _bans_sqlite_rows(limit) or _bans_json_rows(limit)\n        return jsonify({"ok": True, "rows": rows, "source": "sqlite/json" if rows else "none"})\n\n    # Register routes\n    app.add_url_rule("/dashboard/api/phash/upload", view_func=_phash_upload, methods=["POST"])\n    app.add_url_rule("/dashboard/api/metrics-ingest", view_func=_metrics_ingest, methods=["POST"])\n    app.add_url_rule("/dashboard/api/metrics", view_func=_metrics_get, methods=["GET"])\n    app.add_url_rule("/dashboard/api/banned_users", view_func=_banned_users, methods=["GET"])